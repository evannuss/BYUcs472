{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree Lab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYzl0ZP3oP6u"
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9pULAGvobfO"
      },
      "source": [
        "class DTClassifier(BaseEstimator,ClassifierMixin):\n",
        "\n",
        "    def __init__(self,featureNames, counts=None):\n",
        "        \"\"\" Initialize class with chosen hyperparameters.\n",
        "        Args:\n",
        "        Optional Args (Args we think will make your life easier):\n",
        "            counts: A list of Ints that tell you how many types of each feature there are\n",
        "        Example:\n",
        "            DT  = DTClassifier()\n",
        "            or\n",
        "            DT = DTClassifier(count = [2,3,2,2])\n",
        "            Dataset = \n",
        "            [[0,1,0,0],\n",
        "            [1,2,1,1],\n",
        "            [0,1,1,0],\n",
        "            [1,2,0,1],\n",
        "            [0,0,1,1]]\n",
        "\n",
        "        \"\"\"\n",
        "        self.counts = counts\n",
        "        self.featureNames = featureNames\n",
        "\n",
        "        \n",
        "    def calc_entropy(p):\n",
        "      if p != 0:\n",
        "        return -p * np.log2(p)\n",
        "      else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "    def calc_total_entropy(X, y):\n",
        "      entropy = 0.0\n",
        "\n",
        "      classValues = []  \n",
        "      for aclass in y:  \n",
        "        if classValues.count(aclass) == 0:  \n",
        "          classValues.append(aclass) \n",
        "\n",
        "      classCounts = np.zeros(len(classValues))  \n",
        "      classIndex = 0  \n",
        "      for classValue in classValues:  \n",
        "        for aclass in newClasses:  \n",
        "          if aclass == classValue:  \n",
        "            classCounts[classIndex] += 1  \n",
        "        classIndex += 1\n",
        "      self.frequency = np.copy(classCounts)\n",
        "\n",
        "      nData = len(data)\n",
        "      for count in classCounts:\n",
        "        entropy += calc_entropy(count / nData)\n",
        "      \n",
        "      return entropy\n",
        "        \n",
        "\n",
        "    def calc_gain(X,classes,feature):  \n",
        "      gain = 0  \n",
        "      nData = len(data)  \n",
        "\n",
        "      values = []  \n",
        "      for datapoint in data:  \n",
        "        if datapoint[feature] not in values:  \n",
        "          values.append(datapoint[feature])  \n",
        "          \n",
        "      featureCounts = np.zeros(len(values))  \n",
        "      entropy = np.zeros(len(values))\n",
        "      valueIndex = 0  \n",
        "      \n",
        "      for value in values:  \n",
        "        dataIndex = 0  \n",
        "        newClasses = []  \n",
        "        for datapoint in data:  \n",
        "          if datapoint[feature] == value:  \n",
        "            featureCounts[valueIndex] += 1  \n",
        "            newClasses.append(classes[dataIndex])  \n",
        "          dataIndex += 1 \n",
        "\n",
        "        classValues = []  \n",
        "        for aclass in newClasses:  \n",
        "          if classValues.count(aclass) == 0:  \n",
        "            classValues.append(aclass) \n",
        "\n",
        "        classCounts = np.zeros(len(classValues))  \n",
        "        classIndex = 0  \n",
        "        for classValue in classValues:  \n",
        "          for aclass in newClasses:  \n",
        "            if aclass == classValue:  \n",
        "              classCounts[classIndex] += 1  \n",
        "          classIndex += 1 \n",
        "        self.frequency = np.copy(classCounts)\n",
        "\n",
        "        for classIndex in range(len(classValues)):  \n",
        "          entropy[valueIndex] += calc_entropy(float(classCounts[classIndex]) / sum(classCounts))  \n",
        "        gain += float(featureCounts[valueIndex]) / nData * entropy[valueIndex]  \n",
        "        valueIndex += 1  \n",
        "\n",
        "      return gain \n",
        "\n",
        "\n",
        "    def make_tree(X, classes, featureNames):\n",
        "      nData = len(X)\n",
        "      nFeatures = len(featureNames)\n",
        "\n",
        "      totalEntropy = calc_total_entropy(X, classes)\n",
        "\n",
        "      default = classes[np.argmax(self.frequency)]\n",
        "      if nData == 0 or nFeatures == 0:\n",
        "        return default\n",
        "      elif classes.count(classes[0]) == nData:\n",
        "        return classes[0]\n",
        "      else:\n",
        "        gain = np.zeros(nFeatures)\n",
        "        for feature in range(nFeatures):\n",
        "          g = calc_gain(data, classes, feature)\n",
        "          gain[feature] = totalEntropy - g\n",
        "        bestFeature = np.argmax(gain)\n",
        "        tree = {featureNames[bestFeature]:{}}\n",
        "\n",
        "        for val in values:\n",
        "          index = 0\n",
        "          for datapoint in X:\n",
        "            if datapoint[bestFeature] == val:\n",
        "              if bestFeature == 0:\n",
        "                datapoint = datapoint[1:]\n",
        "                newNames = featureNames[1:]\n",
        "              elif bestFeature == nFeatures:\n",
        "                datapoint = datapoint[:-1]\n",
        "                newNames = featureNames[:-1]\n",
        "              else:\n",
        "                datapoint = datapoint[:bestFeature]\n",
        "                datapoint.extend(datapoint[beatFeature+1:])\n",
        "                newNames = featureNames[:bestFeature]\n",
        "                newNames.extend(featureNames[bestFeature+1:])\n",
        "              newData.append(datapoint)\n",
        "              newClasses.append(classes[index])\n",
        "            index += 1\n",
        "\n",
        "          subtree = make_tree(newData, newClasses, newNames)\n",
        "\n",
        "          tree[featureNames[bestFeature]][val] = subtree\n",
        "\n",
        "        return tree\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\" Fit the data; Make the Decision tree\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "            y (array-like): A 1D numpy array with the training targets\n",
        "\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.tree = make_tree(X, y, self.featureNames)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Predict all classes for a dataset X\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "\n",
        "        Returns:\n",
        "            array, shape (n_samples,)\n",
        "                Predicted target values per element in X.\n",
        "        \"\"\"\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\" Return accuracy(Classification Acc) of model on a given dataset. Must implement own score function.\n",
        "\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with data, excluding targets\n",
        "            y (array-like): A 1D numpy array of the targets \n",
        "        \"\"\"\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}